{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FIT101  LIT101  MV101  P101  P102  AIT201  AIT202  AIT203  FIT201  MV201  \\\n",
      "0     0.0     0.0    0.0   0.0   NaN     0.0     0.0     0.0     0.0    0.0   \n",
      "1     0.0     0.0    0.0   0.0   NaN     0.0     0.0     0.0     0.0    0.0   \n",
      "2     0.0     0.0    0.0   0.0   NaN     0.0     0.0     0.0     0.0    0.0   \n",
      "3     0.0     0.0    0.0   0.0   NaN     0.0     0.0     0.0     0.0    0.0   \n",
      "4     0.0     0.0    0.0   0.0   NaN     0.0     0.0     0.0     0.0    0.0   \n",
      "\n",
      "   ...  P501  P502  PIT501  PIT502  PIT503  FIT601  P601  P602  P603  \\\n",
      "0  ...   NaN   NaN     0.0     NaN     0.0     0.0   NaN   NaN   NaN   \n",
      "1  ...   NaN   NaN     0.0     NaN     0.0     0.0   NaN   NaN   NaN   \n",
      "2  ...   NaN   NaN     0.0     NaN     0.0     0.0   NaN   NaN   NaN   \n",
      "3  ...   NaN   NaN     0.0     NaN     0.0     0.0   NaN   NaN   NaN   \n",
      "4  ...   NaN   NaN     0.0     NaN     0.0     0.0   NaN   NaN   NaN   \n",
      "\n",
      "   Normal/Attack  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import math\n",
    "class MultivariateDiscretizer:\n",
    "    def __init__(self, n_bins=10, min_support_diff=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the discretizer.\n",
    "        \n",
    "        Parameters:\n",
    "        - n_bins: Number of initial bins to divide each continuous attribute.\n",
    "        - min_support_diff: Minimum difference in support for merging intervals.\n",
    "        \"\"\"\n",
    "        self.n_bins = n_bins\n",
    "        self.min_support_diff = min_support_diff\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Discretizes the continuous features in the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: A pandas DataFrame with continuous attributes to discretize.\n",
    "        \n",
    "        Returns:\n",
    "        - A pandas DataFrame with discretized continuous variables.\n",
    "        \"\"\"\n",
    "        discretized_data = data.copy()\n",
    "        for col in data.columns:\n",
    "            discretized_data[col] = self._discretize_column(data[col])\n",
    "        return discretized_data\n",
    "\n",
    "    def _discretize_column(self, series):\n",
    "        # Step 1: Initial partitioning into equal-width bins\n",
    "        bins = pd.cut(series, bins=self.n_bins, labels=False)\n",
    "        bin_edges = np.linspace(series.min(), series.max(), self.n_bins + 1)\n",
    "\n",
    "        # Step 2: Merge adjacent intervals based on distribution similarity\n",
    "        while True:\n",
    "            merged = False\n",
    "            for i in range(len(bin_edges) - 2):\n",
    "                interval_data = series[(bins == i) | (bins == i + 1)]\n",
    "                if self._are_distributions_similar(interval_data):\n",
    "                    # Merge bins i and i+1\n",
    "                    bins[bins == i + 1] = i\n",
    "                    bin_edges = np.delete(bin_edges, i + 1)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                break\n",
    "\n",
    "        # Map each original value to the merged bins\n",
    "        discretized_series = pd.cut(series, bins=bin_edges, labels=False)\n",
    "        return discretized_series\n",
    "\n",
    "    def _are_distributions_similar(self, data):\n",
    "        \"\"\"\n",
    "        Tests if the distributions within two intervals are similar.\n",
    "        \n",
    "        Parameters:\n",
    "        - data: Data for the two intervals being tested.\n",
    "        \n",
    "        Returns:\n",
    "        - True if the intervals have similar distributions, otherwise False.\n",
    "        \"\"\"\n",
    "        # Create histogram and add Laplace smoothing to avoid zero counts\n",
    "        counts, _ = np.histogram(data, bins=2)\n",
    "        counts = counts + 0.5  # Laplace smoothing\n",
    "\n",
    "        # Perform chi-square test\n",
    "        _, p_value, _, _ = chi2_contingency([counts])\n",
    "        \n",
    "        # Return True if distributions are similar (p-value > threshold)\n",
    "        return p_value > self.min_support_diff\n",
    "\n",
    "# Example usage:\n",
    "data = pd.read_csv(\"D:/Projects/formal_project/concatenated_SWaT_Dataset.csv\")\n",
    "\n",
    "discretizer = MultivariateDiscretizer(n_bins = 100, min_support_diff=0.05)\n",
    "discretized_data = discretizer.fit(data)\n",
    "\n",
    "print(discretized_data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
