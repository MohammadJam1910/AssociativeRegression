{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "def download_spmf():\n",
    "    \"\"\"Download SPMF jar file if not present\"\"\"\n",
    "    spmf_dir = os.path.join(os.path.expanduser(\"~\"), '.pyspmf')\n",
    "    os.makedirs(spmf_dir, exist_ok=True)\n",
    "    jar_path = os.path.join(spmf_dir, 'spmf.jar')\n",
    "    \n",
    "    if not os.path.exists(jar_path):\n",
    "        url = \"http://www.philippe-fournier-viger.com/spmf/spmf.jar\"\n",
    "        urllib.request.urlretrieve(url, jar_path)\n",
    "    \n",
    "    return jar_path\n",
    "\n",
    "def prepare_data_file(data, output_path):\n",
    "    \"\"\"Save data in SPMF format\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, row in data.iterrows():\n",
    "            line = ' '.join(str(val) for val in row)\n",
    "            f.write(f\"{line}\\n\")\n",
    "\n",
    "def convert_to_transaction_format(df, output_path):\n",
    "    \"\"\"Convert discretized data to SPMF transaction format\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            items = [f\"{col}_{row[col]}\" for col in df.columns]\n",
    "            f.write(f\"{' '.join(items)}\\n\")\n",
    "\n",
    "def read_patterns(patterns_path):\n",
    "    \"\"\"Read and format frequent patterns\"\"\"\n",
    "    patterns = []\n",
    "    with open(patterns_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                pattern, support = line.strip().split(' #SUP: ')\n",
    "                items = pattern.strip().split(' ')\n",
    "                patterns.append({\n",
    "                    'pattern': items,\n",
    "                    'support': int(support)\n",
    "                })\n",
    "    return pd.DataFrame(patterns)\n",
    "\n",
    "def discretize_and_mine_patterns(data, target_column=None, min_support=0.1, java_path='java'):\n",
    "    \"\"\"\n",
    "    Main function to discretize data using MDL and mine patterns using SPMF\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        Input data to process\n",
    "    target_column : str\n",
    "        Name of target column to exclude from discretization\n",
    "    min_support : float\n",
    "        Minimum support threshold (0 to 1)\n",
    "    java_path : str\n",
    "        Path to Java executable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (discretized_df, patterns)\n",
    "    \"\"\"\n",
    "    # Get SPMF jar\n",
    "    spmf_jar = download_spmf()\n",
    "    \n",
    "    # Create temporary directory for files\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Prepare paths\n",
    "        input_path = os.path.join(temp_dir, 'input.txt')\n",
    "        discretized_path = os.path.join(temp_dir, 'discretized.txt')\n",
    "        transactions_path = os.path.join(temp_dir, 'transactions.txt')\n",
    "        patterns_path = os.path.join(temp_dir, 'patterns.txt')\n",
    "        \n",
    "        # Prepare data\n",
    "        features = data.drop(columns=[target_column] if target_column else [])\n",
    "        prepare_data_file(features, input_path)\n",
    "        \n",
    "        # Run MDL discretization\n",
    "        subprocess.call([\n",
    "            java_path,\n",
    "            '-jar', spmf_jar,\n",
    "            'run', 'MDL-Discretizer',\n",
    "            input_path,\n",
    "            discretized_path\n",
    "        ])\n",
    "        \n",
    "        # Read discretized results\n",
    "        discretized_df = pd.read_csv(\n",
    "            discretized_path,\n",
    "            sep=' ',\n",
    "            header=None,\n",
    "            names=features.columns\n",
    "        )\n",
    "        \n",
    "        # Add back target column if exists\n",
    "        if target_column:\n",
    "            discretized_df[target_column] = data[target_column]\n",
    "        \n",
    "        # Convert to transaction format\n",
    "        convert_to_transaction_format(discretized_df, transactions_path)\n",
    "        \n",
    "        # Run pattern mining\n",
    "        abs_min_support = int(min_support * len(discretized_df))\n",
    "        subprocess.call([\n",
    "            java_path,\n",
    "            '-jar', spmf_jar,\n",
    "            'run', 'FPGrowth_itemsets',\n",
    "            transactions_path,\n",
    "            patterns_path,\n",
    "            str(abs_min_support)\n",
    "        ])\n",
    "        \n",
    "        # Read patterns\n",
    "        patterns = read_patterns(patterns_path)\n",
    "        \n",
    "        return discretized_df, patterns\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, n_samples),\n",
    "        'feature2': np.random.exponential(2, n_samples),\n",
    "        'feature3': np.random.uniform(-1, 1, n_samples),\n",
    "        'target': np.random.randint(0, 2, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Run discretization and pattern mining\n",
    "    discretized_df, patterns = discretize_and_mine_patterns(\n",
    "        data=df,\n",
    "        target_column='target',\n",
    "        min_support=0.1\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Original data (first 5 rows):\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDiscretized data (first 5 rows):\")\n",
    "    print(discretized_df.head())\n",
    "    print(\"\\nFrequent patterns (top 5):\")\n",
    "    print(patterns.head())\n",
    "    print(f\"\\nTotal patterns found: {len(patterns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
